{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.applications import ResNet50 \n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D , Dense , Lambda ,Input\n",
    "from tensorflow.keras.models import  Model\n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input  \n",
    "import numpy as np \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet',include_top=False, input_shape=(224,224,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature():\n",
    "    input_layer = Input(shape=(224,224,3))\n",
    "    x = base_model(input_layer)\n",
    "    x= GlobalAveragePooling2D()(x)\n",
    "    return Model(input_layer,x)\n",
    "\n",
    "feature_extractor = create_feature()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_network():\n",
    "    input_1 = Input(shape=(224,224,3))\n",
    "    input_2 = Input(shape=(224,224,3))\n",
    "    \n",
    "    feature_1 = feature_extractor(input_1)\n",
    "    feature_2 = feature_extractor(input_2)\n",
    "\n",
    "    l2_distance = Lambda(lambda tensors : tf.keras.backend.abs(tensors[0]-tensors[1]))([feature_1,feature_2])\n",
    "    x = Dense(512,activation='relu')(l2_distance)\n",
    "    x = Dense(128,activation='relu')(x)\n",
    "\n",
    "    output = Dense(3,activation='softmax')(x)\n",
    "\n",
    "    siamese_model = Model(inputs=[input_1,input_2],outputs=output)\n",
    "\n",
    "    siamese_model.compile(optimizer='adam',loss= 'categorical_crossentropy' ,metrics=['accuracy'])\n",
    "    \n",
    "    return siamese_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_35      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_36      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_31       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ input_layer_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ input_layer_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ functional_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dense_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_35      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_36      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_31       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │ \u001b[38;5;34m23,587,712\u001b[0m │ input_layer_35[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ input_layer_36[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ functional_31[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ functional_31[\u001b[38;5;34m1\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,049,088\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m65,664\u001b[0m │ dense_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,702,851</span> (94.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,702,851\u001b[0m (94.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,649,731</span> (94.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,649,731\u001b[0m (94.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "siamese_model =  build_siamese_network()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\arham\\AppData\\Local\\Temp\\ipykernel_4056\\2853168960.py:1: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  img_path_1 = 'Volunteers Data\\MADAM REHANA\\hand (after 15 days).jpg'  # First image path (before)\n",
      "C:\\Users\\arham\\AppData\\Local\\Temp\\ipykernel_4056\\2853168960.py:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  img_path_2 = 'Volunteers Data\\MADAM REHANA\\hand (after 35 days).jpg'  # Second image path (after)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Prediction: Skin quality has deteriorated.\n"
     ]
    }
   ],
   "source": [
    "img_path_1 = 'Volunteers Data\\MADAM REHANA\\hand (after 15 days).jpg'  # First image path (before)\n",
    "img_path_2 = 'Volunteers Data\\MADAM REHANA\\hand (after 35 days).jpg'  # Second image path (after)\n",
    "\n",
    "img1 = image.load_img(img_path_1, target_size=(224, 224))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1, axis=0)\n",
    "img1 = preprocess_input(img1)\n",
    "\n",
    "img2 = image.load_img(img_path_2, target_size=(224, 224))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2, axis=0)\n",
    "img2 = preprocess_input(img2)\n",
    "\n",
    "# Predict whether the skin quality has improved, deteriorated, or remained the same\n",
    "prediction = siamese_model.predict([img1, img2])\n",
    "\n",
    "# Interpret the prediction\n",
    "class_labels = ['improved', 'no change', 'deteriorated']\n",
    "predicted_class = class_labels[np.argmax(prediction[0])]\n",
    "print(f\"Prediction: Skin quality has {predicted_class}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding pipeline \n",
    "class ImagePairPipeline:\n",
    "    def __init__(self,model,image_size =(224,224,3),preprocess_func =preprocess_input):\n",
    "        self.model = model \n",
    "        self.image_size = image_size\n",
    "        self.preprocess_func = preprocess_func\n",
    "        self.class_labels = ['improved', 'no change', 'deteriorated']\n",
    "\n",
    "    def load_and_preprocess_image(self,img_path):\n",
    "        img = image.load_img(img_path,target_size =self.image_size)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img ,axis=0)\n",
    "        img = self.preprocess_func(img)\n",
    "        return img \n",
    "    \n",
    "    def predict(self , img_path_1 , img_path_2):\n",
    "        img1 = self.load_and_preprocess_image(img_path_1)\n",
    "        img2 = self.load_and_preprocess_image(img_path_2)\n",
    "\n",
    "        prediction = self.model.predict([img1,img2])\n",
    "        return prediction \n",
    "    \n",
    "    def predict_on_pairs(self,img_paths):\n",
    "        predictions = []\n",
    "        for i in range(len(img_paths)-1):\n",
    "            pred = self.predict(img_paths[i],img_paths[i+1])\n",
    "            predictions.append((img_paths[i], img_paths[i + 1], pred))\n",
    "        return predictions  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Prediction between hand (after 15 days).jpg and hand (after 35 days).jpg: Skin quality has deteriorated.\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'Volunteers Data/MADAM REHANA'\n",
    "img_paths = [\n",
    "    os.path.join(img_dir, 'hand (after 15 days).jpg'),\n",
    "    os.path.join(img_dir, 'hand (after 35 days).jpg'),\n",
    "    \n",
    "]\n",
    "\n",
    "pipeline = ImagePairPipeline(siamese_model)\n",
    "\n",
    "predictions = pipeline.predict_on_pairs(img_paths)\n",
    "\n",
    "for img1, img2, pred in predictions:\n",
    "    class_labels = ['improved', 'no change', 'deteriorated']\n",
    "    predicted_class = class_labels[np.argmax(pred)]\n",
    "    print(f\"Prediction between {os.path.basename(img1)} and {os.path.basename(img2)}: Skin quality has {predicted_class}.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "Prediction between head (after 15 days).jpg and head (after 35 days).jpg: Skin quality has deteriorated.\n",
      "Prediction between head (after 35 days).jpg and head 2 (after 35 days).jpg: Skin quality has deteriorated.\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'Volunteers Data/MADAM REHANA'\n",
    "img_paths = [\n",
    "    os.path.join(img_dir, 'head (after 15 days).jpg'),\n",
    "    os.path.join(img_dir, 'head (after 35 days).jpg'),\n",
    "    os.path.join(img_dir, 'head 2 (after 35 days).jpg'),\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "pipeline = ImagePairPipeline(siamese_model)\n",
    "\n",
    "predictions = pipeline.predict_on_pairs(img_paths)\n",
    "\n",
    "for img1, img2, pred in predictions:\n",
    "    class_labels = ['improved', 'no change', 'deteriorated']\n",
    "    predicted_class = class_labels[np.argmax(pred)]\n",
    "    print(f\"Prediction between {os.path.basename(img1)} and {os.path.basename(img2)}: Skin quality has {predicted_class}.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Prediction between L HEAD(0 time).jpg and L HEAD 2(0 time).jpg: Skin quality has deteriorated.\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'Volunteers Data/MADAM REHANA'\n",
    "img_paths = [\n",
    "    os.path.join(img_dir, 'L HEAD(0 time).jpg'),\n",
    "    os.path.join(img_dir, 'L HEAD 2(0 time).jpg'),\n",
    "]\n",
    "\n",
    "pipeline = ImagePairPipeline(siamese_model)\n",
    "\n",
    "predictions = pipeline.predict_on_pairs(img_paths)\n",
    "\n",
    "for img1, img2, pred in predictions:\n",
    "    class_labels = ['improved', 'no change', 'deteriorated']\n",
    "    predicted_class = class_labels[np.argmax(pred)]\n",
    "    print(f\"Prediction between {os.path.basename(img1)} and {os.path.basename(img2)}: Skin quality has {predicted_class}.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
